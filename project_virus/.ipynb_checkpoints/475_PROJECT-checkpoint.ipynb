{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import datetime\n",
    "import operator \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from autograd.misc.flatten import flatten_func\n",
    "from autograd import grad\n",
    "from autograd import hessian\n",
    "from autograd import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "# this is needed to compensate for %matplotl+ib notebook's tendancy to blow up images when plotted inline\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "deaths_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "recoveries_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n",
    "latest_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/06-02-2020.csv')\n",
    "us_medical_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/06-02-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column name of the confirmed numbers\n",
    "cols = confirmed_df.keys()\n",
    "# we focus on the US region\n",
    "confirmed_us = confirmed_df.loc[confirmed_df['Country/Region'] == 'US', :]\n",
    "# print the deathes in US\n",
    "deaths_us = deaths_df.loc[deaths_df['Country/Region'] == 'US', :]\n",
    "# print the recovered people in US\n",
    "recover_us = recoveries_df.loc[recoveries_df['Country/Region'] == 'US', :]\n",
    "confirmed = confirmed_us.loc[:, cols[4]:cols[-1]]\n",
    "deaths = deaths_us.loc[:, cols[4]:cols[-1]]\n",
    "recover = recover_us.loc[:, cols[4]:cols[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = confirmed.keys()\n",
    "\n",
    "us_cases = []\n",
    "us_deaths = [] \n",
    "us_recoveries = [] \n",
    "\n",
    "for i in dates:\n",
    "    us_cases.append(confirmed_df[confirmed_df['Country/Region']=='US'][i].sum())\n",
    "    \n",
    "    us_deaths.append(deaths_df[deaths_df['Country/Region']=='US'][i].sum())\n",
    "    \n",
    "    us_recoveries.append(recoveries_df[recoveries_df['Country/Region']=='US'][i].sum())\n",
    "def daily_increase(data):\n",
    "    d = [] \n",
    "    for i in range(len(data)):\n",
    "        if i == 0:\n",
    "            d.append(data[0])\n",
    "        else:\n",
    "            d.append(data[i]-data[i-1])\n",
    "    return d \n",
    "\n",
    "us_daily_increase = daily_increase(us_cases)\n",
    "us_daily_death = daily_increase(us_deaths)\n",
    "us_daily_recovery = daily_increase(us_recoveries)\n",
    "\n",
    "days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future forecasting\n",
    "days_in_future = 10\n",
    "future_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\n",
    "adjusted_dates = future_forcast[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '1/22/2020'\n",
    "start_date = datetime.datetime.strptime(start, '%m/%d/%Y')\n",
    "future_forcast_dates = []\n",
    "for i in range(len(future_forcast)):\n",
    "    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days_since_1_22, us_cases, test_size=0.3, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train_confirmed, y_train_confirmed)\n",
    "# do the prediction about the \n",
    "linear_test_pred = reg.predict(X_test_confirmed)\n",
    "linear_train_pred = reg.predict(X_train_confirmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform our data for polynomial regression\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "poly_X_train_confirmed = poly.fit_transform(X_train_confirmed)\n",
    "poly_X_test_confirmed = poly.fit_transform(X_test_confirmed)\n",
    "poly_future_forcast = poly.fit_transform(future_forcast)\n",
    "\n",
    "# polynomial regression\n",
    "poly_model = LinearRegression(normalize=True, fit_intercept=False)\n",
    "poly_model.fit(poly_X_train_confirmed, y_train_confirmed)\n",
    "\n",
    "poly_train_pred = poly_model.predict(poly_X_train_confirmed)\n",
    "poly_test_pred = poly_model.predict(poly_X_test_confirmed)\n",
    "poly_future_pred = poly_model.predict(poly_future_forcast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVR(shrinking=True, kernel='poly', gamma=0.01, epsilon=0.1, degree=4, C=0.01)\n",
    "svm_model.fit(X_train_confirmed, y_train_confirmed)\n",
    "\n",
    "svm_test_pred = svm_model.predict(X_test_confirmed)\n",
    "svm_train_pred = svm_model.predict(X_train_confirmed)\n",
    "svm_future_pred = svm_model.predict(future_forcast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-74a4f5e62c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Neural_Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        self.hidden_layer1 = torch.nn.Linear(n_feature, n_hidden)\n",
    "        #self.hidden_layer2 = torch.nn.Linear(n_hidden, int(n_feature/2))\n",
    "        self.predict_layer = torch.nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_result1 = self.hidden_layer1(x)\n",
    "        relu_result1 = F.relu(hidden_result1)\n",
    "        #hidden_result2 = self.hidden_layer2(relu_result1)\n",
    "        #relu_result2 = F.relu(hidden_result2)\n",
    "        predict_result = self.predict_layer(relu_result1)\n",
    "        return predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "TRAIN_TIMES = 2000\n",
    "INPUT_FEATURE_DIM = 1\n",
    "OUTPUT_FEATURE_DIM = 1\n",
    "NEURON_NUM = 64\n",
    "LEARNING_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0f0c10ac8fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#transform all the data into tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_confirmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnn_train_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_confirmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnn_test_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_confirmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnn_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_confirmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#transform all the data into tensor\n",
    "nn_train_x = torch.unsqueeze(torch.Tensor(X_train_confirmed.reshape(-1)), dim=1)\n",
    "nn_train_y = torch.unsqueeze(torch.Tensor(y_train_confirmed), dim=1)\n",
    "nn_test_x = torch.unsqueeze(torch.Tensor(X_test_confirmed.reshape(-1)), dim=1)\n",
    "nn_test_y = torch.unsqueeze(torch.Tensor(y_test_confirmed), dim=1)\n",
    "nn_future_forcast = torch.unsqueeze(torch.Tensor(future_forcast.reshape(-1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Neural_Network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-df209b8d4406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINPUT_FEATURE_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEURON_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_FEATURE_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Neural_Network' is not defined"
     ]
    }
   ],
   "source": [
    "nn_model = Neural_Network(n_feature=INPUT_FEATURE_DIM, n_hidden=NEURON_NUM, n_output=OUTPUT_FEATURE_DIM)\n",
    "print(nn_model)\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "start_time = datetime.datetime.now() \n",
    "for i in range(TRAIN_TIMES):\n",
    "    prediction = nn_model(nn_train_x)\n",
    "\n",
    "    loss = loss_func(prediction, nn_train_y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = datetime.datetime.now() \n",
    "print(\"The time cost for training is {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cc666112e1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnn_future_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_future_forcast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_model' is not defined"
     ]
    }
   ],
   "source": [
    "nn_test_pred = nn_model(nn_test_x).data.numpy()\n",
    "nn_future_pred = nn_model(nn_future_forcast).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.scatter(future_forcast[:-10], us_cases, c = 'blue')\n",
    "# plot the NN prediction\n",
    "plt.plot(future_forcast, nn_future_pred, c = 'yellow')\n",
    "# plot the SVM prediction\n",
    "plt.plot(future_forcast, svm_future_pred, c = 'red')\n",
    "# plot the polynomial prediction\n",
    "plt.plot(future_forcast, poly_future_pred, c = 'purple')\n",
    "#plot the linear regression prediction\n",
    "plt.plot(future_forcast, linear_future_pred, c = 'orange')\n",
    "\n",
    "plt.legend(['Neural Networks Predictions', 'SVM Predictions', 'Polynomial Regression Predictions', 'Linear Regression predictions','Comfirmed cases till now'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
